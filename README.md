# MEgoHand: Multimodal Egocentric Hand-Object Interaction Motion Generation

<div align="center">

[[Website]]()
[[arXiv]](https://arxiv.org/abs/2505.16602)

[![Python Version](https://img.shields.io/badge/Python-3.10-blue.svg)]()
[![GitHub license](https://img.shields.io/badge/MIT-blue)]()

![](docs/assets/head.png)

</div>


We propose MEgoHand, a multimodal framework that synthesizes physically
plausible hand-object interactions from egocentric RGB, text, and initial hand pose. More Visualization can be found on our [[Website]]().


## Code
We will release our code and part of our dataset soon.

## Citation
If you find our work useful, please consider citing us!
```
@inproceedings{zhou2025megohand,
  title={MEgoHand: Multimodal Egocentric Hand-Object Interaction Motion Generation},
  author={Zhou, Bohan and Zhan, Yi and Zhang, Zhongbin and Lu, Zongqing},
  journal={arXiv preprint arXiv:2505.16602},
  year={2025}
}
```